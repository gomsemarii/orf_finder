from flask import Flask, request, jsonify
from flask_cors import CORS
from Bio.Blast import NCBIWWW, NCBIXML
from Bio import Entrez
import io
import csv
import os
from datetime import datetime
import traceback

app = Flask(__name__)
CORS(app)  # Enable CORS for all routes

# Set your email for Entrez (Required by NCBI)
Entrez.email = "your_email@example.com"  # Replace with a valid email or ask user

HISTORY_DIR = 'history'

if not os.path.exists(HISTORY_DIR):
    os.makedirs(HISTORY_DIR)

def get_history_filepath(task_id):
    # Search for a file that ends with _{task_id}.csv
    # This allows us to handle the date prefix dynamically if needed, 
    # but for now we stick to the format used in creation.
    # However, the user might just provide the ID part if we split it, 
    # but the current design uses the full timestamp string as ID.
    # Let's stick to the filename format: yyyymmdd_TaskID.csv
    # But wait, TaskID is date_time. So filename is date_date_time.csv?
    # Let's simplify: The TaskID generated by JS is YYYYMMDD_HHMMSS.
    # We can just use that as the filename: TaskID.csv
    # Or keep the user's request: yyyymmdd_TaskID.csv. 
    # If TaskID is 20231202_120000, then filename is 20231202_20231202_120000.csv? Redundant.
    # Let's use TaskID.csv since TaskID already contains the date.
    return os.path.join(HISTORY_DIR, f"{task_id}.csv")

def init_history_file(task_id, orfs):
    """Creates a new CSV file for the task and initializes it with ORF data."""
    filepath = get_history_filepath(task_id)
    
    with open(filepath, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['ORF_number', 'Timestamp', 'SequenceSnippet', 'Length_aa', 'TopHit', 'Function', 'E_value', 'SequenceFull', 'Strand', 'Frame', 'Start', 'End', 'Length_bp'])
        
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        for orf in orfs:
            writer.writerow([
                orf['orf_number'],
                timestamp,
                orf['protein'][:20] + "..." if len(orf['protein']) > 20 else orf['protein'],
                orf['lengthAa'],
                '', # TopHit
                '', # Function
                '', # E_value
                orf['protein'], # Store full sequence for reloading
                orf.get('strand', '?'),
                orf.get('frame', '?'),
                orf.get('start', '?'),
                orf.get('end', '?'),
                orf.get('lengthBp', '?')
            ])

def update_history_item(task_id, orf_number, result_data):
    """Updates a specific row in the CSV file with BLAST results."""
    filepath = get_history_filepath(task_id)
    
    if not os.path.exists(filepath):
        return False

    rows = []
    updated = False
    
    with open(filepath, 'r', newline='', encoding='utf-8') as f:
        reader = csv.reader(f)
        header = next(reader)
        rows.append(header)
        
        for row in reader:
            if row[0] == str(orf_number):
                # Update columns: TopHit(4), Function(5), E_value(6)
                # Note: Indices might change if we insert columns in the middle, but we appended them.
                # 'ORF_number', 'Timestamp', 'SequenceSnippet', 'Length_aa', 'TopHit', 'Function', 'E_value', ...
                # Indices: 0, 1, 2, 3, 4, 5, 6
                row[4] = result_data['top_hit']
                row[5] = result_data['function']
                row[6] = result_data['e_value']
                updated = True
            rows.append(row)
    
    if updated:
        with open(filepath, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerows(rows)
            
    return updated

def get_gene_summary(accession):
    """Fetches a brief function summary from NCBI Entrez."""
    try:
        handle = Entrez.esummary(db="protein", id=accession, retmode="xml")
        records = Entrez.read(handle)
        handle.close()
        
        if records:
             return records[0].get('Title', 'No summary available')
        return "No summary available"
    except Exception as e:
        print(f"Error fetching summary for {accession}: {e}")
        return "Error fetching summary"

@app.route('/init_task', methods=['POST'])
def init_task():
    try:
        data = request.json
        task_id = data.get('task_id')
        orfs = data.get('orfs')
        
        if not task_id or not orfs:
            return jsonify({'error': 'Missing task_id or orfs'}), 400
            
        init_history_file(task_id, orfs)
        return jsonify({'status': 'success', 'message': f'Task {task_id} initialized'})
        
    except Exception as e:
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/history', methods=['GET'])
def get_history():
    task_id = request.args.get('task_id')
    if not task_id:
        return jsonify({'error': 'Missing task_id'}), 400
        
    filepath = get_history_filepath(task_id)
    if not os.path.exists(filepath):
        return jsonify({'error': 'Task not found'}), 404
        
    try:
        orfs = []
        with open(filepath, 'r', newline='', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                orfs.append({
                    'orf_number': row['ORF_number'],
                    'protein': row['SequenceFull'],
                    'lengthAa': row['Length_aa'],
                    'top_hit': row['TopHit'],
                    'function': row['Function'],
                    'e_value': row['E_value'],
                    'strand': row.get('Strand', '?'),
                    'frame': row.get('Frame', '?'),
                    'start': row.get('Start', '?'),
                    'end': row.get('End', '?'),
                    'lengthBp': row.get('Length_bp', '?')
                })
        return jsonify({'task_id': task_id, 'orfs': orfs})
    except Exception as e:
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/blast', methods=['POST'])
def blast():
    data = request.json
    sequence = data.get('sequence')
    task_id = data.get('task_id')
    orf_number = data.get('orf_number')
    
    if not sequence:
        return jsonify({'error': 'No sequence provided'}), 400
    
    try:
        # Perform BLASTP search against the 'nr' (non-redundant) database
        # Using a smaller database or 'swissprot' might be faster for testing, but 'nr' is standard.
        result_handle = NCBIWWW.qblast("blastp", "nr", sequence)
        
        # Parse the result
        blast_record = NCBIXML.read(result_handle)
        
        if not blast_record.alignments:
            result = {'top_hit': 'No matches found', 'e_value': 'N/A', 'function': 'N/A'}
        else:
            # Get the top hit
            top_alignment = blast_record.alignments[0]
            top_hsp = top_alignment.hsps[0]
            
            # Get Accession for Entrez
            accession = top_alignment.accession
            
            # Get Function Summary
            function_summary = get_gene_summary(accession)
            
            result = {
                'top_hit': top_alignment.title,
                'e_value': str(top_hsp.expect),
                'accession': accession,
                'function': function_summary
            }
        
        # Update History if task_id is present
        if task_id and orf_number:
            update_history_item(task_id, orf_number, result)
        
        return jsonify(result)

    except Exception as e:
        traceback.print_exc()
        print(f"Error during BLAST: {e}")
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    print("Starting BLAST server on http://localhost:5000")
    app.run(debug=True, port=5000)
